{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T05:13:34.718974Z",
     "start_time": "2021-02-03T05:13:33.989537Z"
    }
   },
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import fasttext.util\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T05:13:40.736295Z",
     "start_time": "2021-02-03T05:13:34.720776Z"
    }
   },
   "outputs": [],
   "source": [
    "ft = fasttext.load_model('data/cc.ht.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T17:40:13.051612Z",
     "start_time": "2021-01-26T17:40:13.015024Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['</s>',\n",
       " '.',\n",
       " 'nan',\n",
       " '\"',\n",
       " ',',\n",
       " 'yon',\n",
       " ':',\n",
       " \"'\",\n",
       " 'se',\n",
       " 'vil',\n",
       " ')',\n",
       " '(',\n",
       " 'eta',\n",
       " 'yo',\n",
       " 'peyi',\n",
       " 'moun',\n",
       " 'ki',\n",
       " 'li',\n",
       " 'te',\n",
       " 'ak',\n",
       " 'Etazini',\n",
       " 'de',\n",
       " 'pwovens',\n",
       " 'Kiba',\n",
       " 'lane',\n",
       " 'a',\n",
       " 'genyen',\n",
       " '}',\n",
       " 'pou',\n",
       " '_',\n",
       " 'nonm',\n",
       " 'Li',\n",
       " 'la',\n",
       " 'l',\n",
       " 'an',\n",
       " '2000',\n",
       " 'almanak',\n",
       " 'the',\n",
       " '/',\n",
       " 'Se',\n",
       " 'ant',\n",
       " 'Kategori',\n",
       " 'sistèm',\n",
       " 'Nan',\n",
       " 'natirèl',\n",
       " 'antye',\n",
       " 'sa',\n",
       " 'kèk',\n",
       " ';',\n",
       " 'jilyen',\n",
       " '\\\\',\n",
       " '%',\n",
       " 'La',\n",
       " 'pa',\n",
       " 'gen',\n",
       " 'and',\n",
       " '’',\n",
       " 'non',\n",
       " '-',\n",
       " 'to',\n",
       " 'New',\n",
       " 'ane',\n",
       " 'of',\n",
       " 'Gade',\n",
       " 'sou',\n",
       " 'd',\n",
       " '--',\n",
       " 'in',\n",
       " 'osi',\n",
       " 'del',\n",
       " 'fè',\n",
       " 'ayisyen',\n",
       " 'if',\n",
       " 'then',\n",
       " 'n',\n",
       " 'khi',\n",
       " 'is',\n",
       " 'ap',\n",
       " 'ː',\n",
       " 'Lonjitid',\n",
       " 'et',\n",
       " 'popilasyon',\n",
       " 'kòm',\n",
       " '2',\n",
       " 'itilize',\n",
       " 'El',\n",
       " 'Texas',\n",
       " 'local',\n",
       " 'Nou',\n",
       " 'ekri',\n",
       " 'e',\n",
       " 'York',\n",
       " 'ou',\n",
       " 'for',\n",
       " 'Latitid',\n",
       " 'avèk',\n",
       " 'ke',\n",
       " 'Yon',\n",
       " 'matematisyen',\n",
       " 'bagay',\n",
       " 'à',\n",
       " 'en',\n",
       " '1',\n",
       " 'konte',\n",
       " 'or',\n",
       " 'Habana',\n",
       " 'yòk',\n",
       " 'gregoryen',\n",
       " 'Pou',\n",
       " 'ka',\n",
       " 'epi',\n",
       " 'tout',\n",
       " '?',\n",
       " 'fèt',\n",
       " '2002',\n",
       " '2004',\n",
       " 'lòt',\n",
       " 'le',\n",
       " 's',\n",
       " 'soti',\n",
       " 'Rio',\n",
       " 'Pinar',\n",
       " 'Wisconsin',\n",
       " 'pi',\n",
       " '–',\n",
       " 'chif',\n",
       " '#',\n",
       " 'on',\n",
       " 'arab',\n",
       " 'Pennsilvani',\n",
       " 'lè',\n",
       " 'Matanzas',\n",
       " 'Las',\n",
       " 'atis',\n",
       " 'dinò',\n",
       " 'desimal',\n",
       " 'des',\n",
       " 'Ayiti',\n",
       " 'ekzadesimal',\n",
       " 'lang',\n",
       " 'dyodesimal',\n",
       " 'Image',\n",
       " 'y',\n",
       " 'Missouri',\n",
       " 'The',\n",
       " 'oswa',\n",
       " 'Ohio',\n",
       " 'right',\n",
       " '2005',\n",
       " '2001',\n",
       " 'tankou',\n",
       " '2003',\n",
       " 'franse',\n",
       " 'nou',\n",
       " '+',\n",
       " '..',\n",
       " 'anpil',\n",
       " 'kote',\n",
       " 'Popilasyon',\n",
       " 'pent',\n",
       " 'Minnesota',\n",
       " 'du',\n",
       " '^',\n",
       " 'Clara',\n",
       " 'Villa',\n",
       " 'di',\n",
       " 'Kawolin',\n",
       " '0',\n",
       " '!',\n",
       " 'not',\n",
       " 't',\n",
       " 'ti',\n",
       " 'return',\n",
       " 'tou',\n",
       " 'rejyon',\n",
       " 'oubyen',\n",
       " 'kapab',\n",
       " 'that',\n",
       " 'rele',\n",
       " 'you',\n",
       " 'Camaguey',\n",
       " 'Le',\n",
       " 'Dakota',\n",
       " 'San',\n",
       " 'les',\n",
       " 'Santiago',\n",
       " 'this',\n",
       " 'disid',\n",
       " 'm',\n",
       " 'un',\n",
       " 'men',\n",
       " 'p',\n",
       " '2007',\n",
       " 'Cuba',\n",
       " '2006',\n",
       " 'Franse',\n",
       " 'bay',\n",
       " 'be',\n",
       " '2008',\n",
       " 'Holguin',\n",
       " 'I',\n",
       " 'are',\n",
       " 'Ciego',\n",
       " 'function',\n",
       " 'menm',\n",
       " '2010',\n",
       " 'gwo',\n",
       " 'Oregon',\n",
       " 'pase',\n",
       " 'Oklahoma',\n",
       " 'with',\n",
       " 'jou',\n",
       " 'Tunas',\n",
       " 'Avila',\n",
       " 'km',\n",
       " 'lan',\n",
       " 'Dat',\n",
       " 'Angle',\n",
       " 'Granma',\n",
       " '3',\n",
       " 'sitye',\n",
       " 'premye',\n",
       " 'Lòt',\n",
       " '1905',\n",
       " '2009',\n",
       " 'Alman',\n",
       " 'plis',\n",
       " 'ekriven',\n",
       " 'Panyòl',\n",
       " 'Nebraska',\n",
       " 'Les',\n",
       " 'si',\n",
       " 'Jersey',\n",
       " 'L',\n",
       " 'reyalizatè',\n",
       " 'dans',\n",
       " 'Cienfuegos',\n",
       " 'oktal',\n",
       " 'it',\n",
       " 'from',\n",
       " 'san',\n",
       " 'èkh',\n",
       " '2011',\n",
       " 'left',\n",
       " 'at',\n",
       " '2014',\n",
       " 'UTC',\n",
       " 'error',\n",
       " 'ameriken',\n",
       " '2012',\n",
       " 'Los',\n",
       " 'est',\n",
       " '2016',\n",
       " 'el',\n",
       " 'pour',\n",
       " 'kreyòl',\n",
       " 'pati',\n",
       " 'date',\n",
       " 'amor',\n",
       " 'Sipèfisi',\n",
       " 'une',\n",
       " 'by',\n",
       " 'as',\n",
       " 'text',\n",
       " 'pran',\n",
       " '2013',\n",
       " 'tan',\n",
       " 'rive',\n",
       " 'Riemann',\n",
       " '«',\n",
       " '»',\n",
       " 'A',\n",
       " 'ha',\n",
       " 'byen',\n",
       " '²',\n",
       " 'travay',\n",
       " 'und',\n",
       " 'Bernhard',\n",
       " 'èh',\n",
       " 'me',\n",
       " 'kò',\n",
       " 'que',\n",
       " 'will',\n",
       " 'i',\n",
       " '~',\n",
       " 'Schwere',\n",
       " 'Elektricität',\n",
       " 'Magnetismus',\n",
       " 'value',\n",
       " 'set',\n",
       " 'Sancti',\n",
       " '4',\n",
       " 'vin',\n",
       " 'w',\n",
       " 'can',\n",
       " 'Non',\n",
       " 'Santa',\n",
       " 'dlo',\n",
       " 'Spiritus',\n",
       " 'Guantanamo',\n",
       " 'Washington',\n",
       " 'do',\n",
       " 'gwoup',\n",
       " 'syantifik',\n",
       " 'maladi',\n",
       " 'mete',\n",
       " 'mo',\n",
       " '1999',\n",
       " 'apre',\n",
       " 'pandan',\n",
       " '1998',\n",
       " 'vini',\n",
       " 'kapital',\n",
       " 'no',\n",
       " 'frac',\n",
       " 'jwenn',\n",
       " 'ale',\n",
       " '10',\n",
       " 'bon',\n",
       " 'Jean',\n",
       " 'konnen',\n",
       " 'vle',\n",
       " 'Tennessee',\n",
       " '2015',\n",
       " 'manje',\n",
       " 'have',\n",
       " 'té',\n",
       " 'fanm',\n",
       " 'Espay',\n",
       " 'style',\n",
       " 'k',\n",
       " 'meinme',\n",
       " 'mas',\n",
       " 'par',\n",
       " 'yeou',\n",
       " 'sur',\n",
       " '1996',\n",
       " 'seid',\n",
       " 'Ayisyen',\n",
       " 'pale',\n",
       " 'dwe',\n",
       " 'str',\n",
       " 'name',\n",
       " '>',\n",
       " 'page',\n",
       " 'City',\n",
       " 'kont',\n",
       " 'ta',\n",
       " 'liv',\n",
       " 'komin',\n",
       " 'year',\n",
       " 'Haïti',\n",
       " 'nil',\n",
       " 'This',\n",
       " 'IMDB',\n",
       " '1997',\n",
       " 'plizyè',\n",
       " 'Moun',\n",
       " '...',\n",
       " 'Mo',\n",
       " 'hou',\n",
       " 'Mississippi',\n",
       " 'Yo',\n",
       " 'bisektil',\n",
       " '1995',\n",
       " 'chak',\n",
       " 'il',\n",
       " '$',\n",
       " 'we',\n",
       " 'afriken',\n",
       " '12',\n",
       " 'your',\n",
       " 'María',\n",
       " 'tè',\n",
       " 'zha',\n",
       " '6',\n",
       " 'reprezante',\n",
       " 'khe',\n",
       " 'Sa',\n",
       " 'au',\n",
       " '”',\n",
       " 'kantite',\n",
       " 'plant',\n",
       " '15',\n",
       " 'wiki',\n",
       " 'jan',\n",
       " '“',\n",
       " '1992',\n",
       " 'toujou',\n",
       " 'list',\n",
       " 'youn',\n",
       " 'dyaspora',\n",
       " 'enfeksyon',\n",
       " '1993',\n",
       " 'al',\n",
       " 'aktè',\n",
       " 'rete',\n",
       " 'Utah',\n",
       " '1991',\n",
       " '1994',\n",
       " 'depi',\n",
       " 'tèt',\n",
       " 'apy',\n",
       " '1990',\n",
       " 'Ou',\n",
       " 'Nesans',\n",
       " 'has',\n",
       " 'kh',\n",
       " '5',\n",
       " 'yeo',\n",
       " 'string',\n",
       " 'wè',\n",
       " 'zòn',\n",
       " 'mwen',\n",
       " 'Khe',\n",
       " 'lèt',\n",
       " 'all',\n",
       " 'http',\n",
       " 'Juan',\n",
       " 'Haitian',\n",
       " 'fòme',\n",
       " 'An',\n",
       " 'language',\n",
       " 'match',\n",
       " 'mouri',\n",
       " 'pas',\n",
       " 'viv',\n",
       " 'Si',\n",
       " 'Hampshire',\n",
       " 'Vermont',\n",
       " 'lès',\n",
       " 'anba',\n",
       " 'politik',\n",
       " 'elseif',\n",
       " 'mwa',\n",
       " 'Fichye',\n",
       " '7',\n",
       " 'fanmi',\n",
       " '14',\n",
       " 'Vil',\n",
       " 'Vijini',\n",
       " 'message',\n",
       " '20',\n",
       " 'janvye',\n",
       " 'Paris',\n",
       " 'paske',\n",
       " 'link',\n",
       " 'son',\n",
       " 'If',\n",
       " 'one',\n",
       " 'Wikipedia',\n",
       " 'File',\n",
       " 'avril',\n",
       " 'Pòtoprens',\n",
       " 'table',\n",
       " 'parameter',\n",
       " 'De',\n",
       " 'José',\n",
       " 'angle',\n",
       " 'type',\n",
       " 'M',\n",
       " 'Sifas',\n",
       " 'ladan',\n",
       " 'anvan',\n",
       " 'jwe',\n",
       " 'mizik',\n",
       " 'fòm',\n",
       " 'jiyè',\n",
       " 'qui',\n",
       " 'discussion',\n",
       " 'times',\n",
       " 'true',\n",
       " 'bèt',\n",
       " 'Haiti',\n",
       " 'su',\n",
       " '1987',\n",
       " 'fòs',\n",
       " '0.00',\n",
       " 'yeon',\n",
       " 'Lè',\n",
       " 'atik',\n",
       " 'month',\n",
       " 'ansanm',\n",
       " '1986',\n",
       " 'kòmanse',\n",
       " 'out',\n",
       " 'laten',\n",
       " 'chimik',\n",
       " 'alman',\n",
       " 'Bolivar',\n",
       " 'gouvènman',\n",
       " '8',\n",
       " '18',\n",
       " 'Televisa',\n",
       " 'kay',\n",
       " 'CS1',\n",
       " 'kat',\n",
       " 'timoun',\n",
       " 'use',\n",
       " 'sèl',\n",
       " 'Gen',\n",
       " '1989',\n",
       " 'https',\n",
       " 'En',\n",
       " 'sèlman',\n",
       " 'ow',\n",
       " 'avec',\n",
       " 'Eta',\n",
       " 'Km',\n",
       " '1988',\n",
       " '2017',\n",
       " 'guen',\n",
       " 'args',\n",
       " 'other',\n",
       " 'Module',\n",
       " 'fwa',\n",
       " '100',\n",
       " 'abitan',\n",
       " 'fin',\n",
       " 'souvan',\n",
       " 'ann',\n",
       " 'diferan',\n",
       " 'gason',\n",
       " 'N',\n",
       " 'fevriye',\n",
       " 'code',\n",
       " 'lavi',\n",
       " 'number',\n",
       " '—',\n",
       " 'L.',\n",
       " 'prezidan',\n",
       " 'piti',\n",
       " 'fi',\n",
       " 'resevwa',\n",
       " 'Lake',\n",
       " 'kite',\n",
       " 'v',\n",
       " 'j',\n",
       " 'eleman',\n",
       " 'new',\n",
       " 'id',\n",
       " 'jen',\n",
       " 'ye',\n",
       " 'konsa',\n",
       " 'but',\n",
       " 'enpòtan',\n",
       " 'desanm',\n",
       " 'You',\n",
       " 'nenpòt',\n",
       " 'pye',\n",
       " 'Bondye',\n",
       " 'kreye',\n",
       " 'first',\n",
       " 'used',\n",
       " 'andedan',\n",
       " 'pâ',\n",
       " '13',\n",
       " '11',\n",
       " '•',\n",
       " 'kalite',\n",
       " 'devlope',\n",
       " '9',\n",
       " 'alfabèt',\n",
       " 'more',\n",
       " '22',\n",
       " 'sèvi',\n",
       " 'parameters',\n",
       " 'when',\n",
       " '1980',\n",
       " 'mizisyen',\n",
       " 'Un',\n",
       " 'also',\n",
       " 'title',\n",
       " 'll-l',\n",
       " '1985',\n",
       " 'selil',\n",
       " 'so',\n",
       " 'Carlos',\n",
       " '1979',\n",
       " 'dat',\n",
       " '17',\n",
       " '25',\n",
       " 'woman',\n",
       " 'pouvwa',\n",
       " '30',\n",
       " 'pitit',\n",
       " 'Creole',\n",
       " 'about',\n",
       " 'Imaj',\n",
       " 'lwa',\n",
       " 'septanm',\n",
       " 'mound',\n",
       " 'bezwen',\n",
       " 'los',\n",
       " '21',\n",
       " 'gaan',\n",
       " '1983',\n",
       " 'pèmèt',\n",
       " '16',\n",
       " 'ah',\n",
       " 'paj',\n",
       " 'pwodui',\n",
       " 'English',\n",
       " 'Sen',\n",
       " 'ni',\n",
       " 'lakòz',\n",
       " 'kwè',\n",
       " 'now',\n",
       " 'It',\n",
       " 'Men',\n",
       " 'touth',\n",
       " '19',\n",
       " 'Amerik',\n",
       " '1982',\n",
       " 'oktòb',\n",
       " 'mi',\n",
       " 'machin',\n",
       " 'help',\n",
       " 'mèt',\n",
       " 'twa',\n",
       " 'Chèf-lye',\n",
       " 'mal',\n",
       " 'Mi',\n",
       " 'end',\n",
       " 'ansyen',\n",
       " 'was',\n",
       " '&',\n",
       " 'article',\n",
       " '29',\n",
       " 'ISBN',\n",
       " 'montre',\n",
       " 'glif',\n",
       " 'chantè',\n",
       " 'langue',\n",
       " 'ede',\n",
       " 'moso',\n",
       " 'kenbe',\n",
       " 'nouvo',\n",
       " 'val',\n",
       " 'rapò',\n",
       " 'ba',\n",
       " 'ofisyèl',\n",
       " 'objè',\n",
       " 'Amor',\n",
       " 'sòti',\n",
       " 'Joseph',\n",
       " 'es',\n",
       " 'politisyen',\n",
       " 'fason',\n",
       " 'gran',\n",
       " 'Yeo',\n",
       " 'editor',\n",
       " 'mouvman',\n",
       " 'fe',\n",
       " 'mande',\n",
       " '1984',\n",
       " 'D',\n",
       " '1981',\n",
       " 'there',\n",
       " 'David',\n",
       " 'been',\n",
       " 'lajan',\n",
       " 'West',\n",
       " 'awondisman',\n",
       " 'o',\n",
       " 'pages',\n",
       " 'any',\n",
       " 'x',\n",
       " 'like',\n",
       " 'lekòl',\n",
       " 'Repiblik',\n",
       " 'manman',\n",
       " 'britanik',\n",
       " 'Saint',\n",
       " 'url',\n",
       " 'Afrik',\n",
       " 'Pierre',\n",
       " 'mond',\n",
       " 'Montana',\n",
       " 'pote',\n",
       " 'Il',\n",
       " 'sans',\n",
       " 'chanje',\n",
       " 'pral',\n",
       " 'make',\n",
       " 'which',\n",
       " 'López',\n",
       " 'òganis',\n",
       " 'enèji',\n",
       " 'Bolívar',\n",
       " 'renmen',\n",
       " 'sibstans',\n",
       " 'las',\n",
       " 'false',\n",
       " 'fizisyen',\n",
       " 'round',\n",
       " 'University',\n",
       " 'citation',\n",
       " 'long',\n",
       " 'pwoblèm',\n",
       " 'Antonio',\n",
       " 'only',\n",
       " 'Tout',\n",
       " '23',\n",
       " 'Wikimedia',\n",
       " 'vida',\n",
       " 'result',\n",
       " 'frame',\n",
       " 'depatman',\n",
       " 'Charles',\n",
       " 'anlè',\n",
       " 'konsidere',\n",
       " '24',\n",
       " 'pozisyon',\n",
       " 'fini',\n",
       " 'aux',\n",
       " '27',\n",
       " 'sifas',\n",
       " 'see',\n",
       " 'Please',\n",
       " 'Pari',\n",
       " 'Ewòp',\n",
       " '28',\n",
       " 'nesans',\n",
       " 'Kapital',\n",
       " 'template',\n",
       " 'add',\n",
       " 'istwa',\n",
       " 'names',\n",
       " 'imaj',\n",
       " 'ne',\n",
       " 'direksyon',\n",
       " 'Luis',\n",
       " 'milyon',\n",
       " 'too',\n",
       " 'Jacques',\n",
       " 'North',\n",
       " 'In',\n",
       " 'antre',\n",
       " 'teid',\n",
       " 'category',\n",
       " 'mache',\n",
       " 'last',\n",
       " '26',\n",
       " 'should',\n",
       " 'please',\n",
       " 'get',\n",
       " 'tete',\n",
       " 'Kèk',\n",
       " 'pah',\n",
       " 'Park',\n",
       " 'France',\n",
       " 'Ki',\n",
       " 'day',\n",
       " 'parèt',\n",
       " 'minis',\n",
       " 'wo',\n",
       " 'Soria',\n",
       " 'etid',\n",
       " 'format',\n",
       " 'dwa',\n",
       " 'plus',\n",
       " 'etidye',\n",
       " 'kontinye',\n",
       " 'image',\n",
       " 'zile',\n",
       " 'Ti',\n",
       " 'We',\n",
       " 'leta',\n",
       " 'novanm',\n",
       " 'solid',\n",
       " 'kominote',\n",
       " 'syèk',\n",
       " 'bouch',\n",
       " 'Nevada',\n",
       " 'militè',\n",
       " '200',\n",
       " 'tounen',\n",
       " 'kansè',\n",
       " 'prensipal',\n",
       " '1978',\n",
       " 'aksyon',\n",
       " 'cette',\n",
       " 'source',\n",
       " 'edit',\n",
       " 'laj',\n",
       " 'deplase',\n",
       " 'chanjman',\n",
       " 'pâr',\n",
       " 'gade',\n",
       " 'likid',\n",
       " 'here',\n",
       " 'sont',\n",
       " 'bwa',\n",
       " 'trè',\n",
       " 'Frans',\n",
       " 'Dos',\n",
       " '31',\n",
       " 'touye',\n",
       " 'kap',\n",
       " 'rezilta',\n",
       " '1975',\n",
       " 'French',\n",
       " 'syans',\n",
       " 'lòd',\n",
       " 'test',\n",
       " 'some',\n",
       " 'Inivèsite',\n",
       " 'je',\n",
       " 'selon',\n",
       " 'janm',\n",
       " 'rfloor',\n",
       " 'may',\n",
       " 'done',\n",
       " 'para',\n",
       " 'manm',\n",
       " 'To',\n",
       " 'bebe',\n",
       " 'qu',\n",
       " 'jeneral',\n",
       " 'lanmò',\n",
       " 'valid',\n",
       " 'wòch',\n",
       " '1977',\n",
       " 'nasyonal',\n",
       " 'sosyete',\n",
       " 'latè',\n",
       " 'mitan',\n",
       " 'egzanp',\n",
       " '1974',\n",
       " 'bò',\n",
       " 'Daniel',\n",
       " 'Pages',\n",
       " 'Pa',\n",
       " 'Jezi',\n",
       " 'Kanada',\n",
       " 'legliz',\n",
       " 'c',\n",
       " 'pèp',\n",
       " 'yonn',\n",
       " 'pwent',\n",
       " 'South',\n",
       " 'pairs',\n",
       " 'templates',\n",
       " 'chèf',\n",
       " 'patisipe',\n",
       " 'II',\n",
       " 'center',\n",
       " 'egziste',\n",
       " 'aktivite',\n",
       " 'trete',\n",
       " 'etc',\n",
       " 'tonumber',\n",
       " 'information',\n",
       " 'Premye',\n",
       " 'lis',\n",
       " 'Pedro',\n",
       " '0.4em',\n",
       " 'aktris',\n",
       " '…',\n",
       " 'koulè',\n",
       " 'modèl',\n",
       " 'VisualEditor',\n",
       " 'vivan',\n",
       " 'Ana',\n",
       " '1976',\n",
       " '1968',\n",
       " 'Venevisión',\n",
       " 'guenllein',\n",
       " 'pwen',\n",
       " 'ankò',\n",
       " 'Wyoming',\n",
       " 'baze',\n",
       " '1973',\n",
       " 'rantre',\n",
       " 'italyen',\n",
       " 'mennen',\n",
       " 'links',\n",
       " 'Apre',\n",
       " 'limyè',\n",
       " '1970',\n",
       " 'Wikipedya',\n",
       " 'Don',\n",
       " 'Ozetazini',\n",
       " 'sanble',\n",
       " 'Valley',\n",
       " 'Corazón',\n",
       " 'Miguel',\n",
       " 'konsène',\n",
       " 'Michel',\n",
       " 'grèk',\n",
       " 'Peyi',\n",
       " 'fou',\n",
       " 'Manuel',\n",
       " 'Batey',\n",
       " 'kòd',\n",
       " 'televizyon',\n",
       " 'part',\n",
       " 'S',\n",
       " 'sentòm',\n",
       " 'Venezyela',\n",
       " '1972',\n",
       " 'konn',\n",
       " 'mujer',\n",
       " 'my',\n",
       " 'fò',\n",
       " 'Gabriel',\n",
       " 'pwosesis',\n",
       " 'kounye',\n",
       " 'sous',\n",
       " 'endepandans',\n",
       " 'lame',\n",
       " 'move',\n",
       " 'Louis',\n",
       " 'peryòd',\n",
       " 'bakteri',\n",
       " 'fizik',\n",
       " 'solèy',\n",
       " 'planèt',\n",
       " 'ajan',\n",
       " 'deja',\n",
       " 'editors',\n",
       " 'tonbe',\n",
       " 'bot',\n",
       " '1969',\n",
       " 'Telemundo',\n",
       " 'voye',\n",
       " 'nivo',\n",
       " 'plas',\n",
       " '─',\n",
       " 'avek',\n",
       " 'images',\n",
       " 'Mwen',\n",
       " 'appou',\n",
       " 'Creek',\n",
       " 'enfòmasyon',\n",
       " 'Francisco',\n",
       " '1000',\n",
       " 'Isabel',\n",
       " 'Komin',\n",
       " 'John',\n",
       " 'anpeche',\n",
       " 'òganizasyon',\n",
       " 'TV',\n",
       " 'table.insert',\n",
       " 'Macintosh',\n",
       " 'konesans',\n",
       " 'precision',\n",
       " 'Karayib',\n",
       " 'Jan',\n",
       " 'Anpil',\n",
       " 'top',\n",
       " 'two',\n",
       " 'total',\n",
       " 'East',\n",
       " 'Rosa',\n",
       " 'ses',\n",
       " 'Me',\n",
       " 'panse',\n",
       " 'fonksyon',\n",
       " 'tap',\n",
       " 'articles',\n",
       " 'Wikidata',\n",
       " 'sum',\n",
       " 'dezyèm',\n",
       " 'Risi',\n",
       " 'tay',\n",
       " 'need',\n",
       " 'than',\n",
       " 'po',\n",
       " 'text-align',\n",
       " 'sant',\n",
       " 'cite',\n",
       " 'would',\n",
       " 'grandi',\n",
       " 'RCTV',\n",
       " 'tretman',\n",
       " 'medikaman',\n",
       " 'data',\n",
       " 'Liv',\n",
       " 'pèdi',\n",
       " 'edisyon',\n",
       " 'ogmante',\n",
       " 'Kreyòl',\n",
       " 'Lang',\n",
       " 'bar',\n",
       " 'fim',\n",
       " 'matematik',\n",
       " '1957',\n",
       " 'endikatif',\n",
       " 'available',\n",
       " 'Nasyonal',\n",
       " 'devlopman',\n",
       " 'Marie',\n",
       " 'errors',\n",
       " 'okenn',\n",
       " 'jis',\n",
       " 'kontinan',\n",
       " 'vignette',\n",
       " 'pat',\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T04:51:36.937077Z",
     "start_time": "2021-01-26T04:51:36.656538Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ft' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4d6d501636f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_word_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ft' is not defined"
     ]
    }
   ],
   "source": [
    "ft.get_word_vector('fle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-09T20:10:41.679700Z",
     "start_time": "2021-01-09T20:10:40.759337Z"
    }
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: EOF inside string starting at row 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-94460df932a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/cc.ht.300.vec'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2035\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2036\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2037\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2038\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: EOF inside string starting at row 4"
     ]
    }
   ],
   "source": [
    "pd.read_csv('data/cc.ht.300.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T02:21:22.919983Z",
     "start_time": "2021-01-14T01:50:27.639010Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# stream_url = 'https://node-24.zeno.fm/54k0v7x14neuv?rj-ttl=5&rj-tok=AAABdulgsqMAZQZWFeQSsTHY_A'\n",
    "# stream_url = 'https://node-15.zeno.fm/54k0v7x14neuv?rj-ttl=5&rj-tok=AAABdv6a_v0Aw7ztClNLYwOOjg'\n",
    "stream_url = 'https://stream.zenolive.com/4sqccruhey5tv' # Radio RCH 2000\n",
    "\n",
    "r = requests.get(stream_url, stream=True)\n",
    "\n",
    "with open('recording_newlink.mp3', 'wb') as f:\n",
    "    try:\n",
    "        for block in r.iter_content(1024):\n",
    "            f.write(block)\n",
    "    except KeyboardInterrupt:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T03:57:33.451515Z",
     "start_time": "2021-01-12T03:57:33.445823Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.61538461538461"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "60/3.9 * 4.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_url = 'https://speech.googleapis.com/v1p1beta1/speech:recognize'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T03:48:23.122694Z",
     "start_time": "2021-01-14T03:48:23.108687Z"
    }
   },
   "outputs": [],
   "source": [
    "def transcribe_file(speech_file):\n",
    "    \"\"\"Transcribe the given audio file asynchronously.\"\"\"\n",
    "    from google.cloud import speech\n",
    "\n",
    "    client = speech.SpeechClient.from_service_account_json('/Users/adimaini/Documents/GW/Machine Learning/Research/FastText.nosync/Google speech-to-text/My Project 16457-e96d5cc9e81c.json')\n",
    "    \n",
    "    with io.open(speech_file, \"rb\") as audio_file:\n",
    "        content = audio_file.read()\n",
    "\n",
    "    \"\"\"\n",
    "     Note that transcription is limited to a 60 seconds audio file.\n",
    "     Use a GCS file for audio longer than 1 minute.\n",
    "    \"\"\"\n",
    "    audio = speech.RecognitionAudio(content=content)\n",
    "\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=16000,\n",
    "        language_code=\"fr-FR\",\n",
    "    )\n",
    "\n",
    "\n",
    "    operation = client.long_running_recognize(config=config, audio=audio)\n",
    "\n",
    "    print(\"Waiting for operation to complete...\")\n",
    "    response = operation.result(timeout=90)\n",
    "\n",
    "    # Each result is for a consecutive portion of the audio. Iterate through\n",
    "    # them to get the transcripts for the entire audio file.\n",
    "    for result in response.results:\n",
    "        # The first alternative is the most likely one for this portion.\n",
    "        print(u\"Transcript: {}\".format(result.alternatives[0].transcript))\n",
    "        print(\"Confidence: {}\".format(result.alternatives[0].confidence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T03:48:35.223169Z",
     "start_time": "2021-01-14T03:48:23.295292Z"
    }
   },
   "outputs": [
    {
     "ename": "InvalidArgument",
     "evalue": "400 Request payload size exceeds the limit: 10485760 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    825\u001b[0m                                       wait_for_ready, compression)\n\u001b[0;32m--> 826\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.INVALID_ARGUMENT\n\tdetails = \"Request payload size exceeds the limit: 10485760 bytes.\"\n\tdebug_error_string = \"{\"created\":\"@1610596115.183092000\",\"description\":\"Error received from peer ipv4:172.217.9.234:443\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Request payload size exceeds the limit: 10485760 bytes.\",\"grpc_status\":3}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d217c4460cc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mspeech_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/adimaini/Documents/GW/Machine Learning/Research/FastText.nosync/Radio RCH2000.mp3'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtranscribe_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeech_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-285e01a9671e>\u001b[0m in \u001b[0;36mtranscribe_file\u001b[0;34m(speech_file)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0moperation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong_running_recognize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Waiting for operation to complete...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/google/cloud/speech_v1/services/speech/client.py\u001b[0m in \u001b[0;36mlong_running_recognize\u001b[0;34m(self, request, config, audio, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrpc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;31m# Wrap the response in an operation future.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgument\u001b[0m: 400 Request payload size exceeds the limit: 10485760 bytes."
     ]
    }
   ],
   "source": [
    "import io\n",
    "speech_file = '/Users/adimaini/Documents/GW/Machine Learning/Research/FastText.nosync/Radio RCH2000.mp3'\n",
    "transcribe_file(speech_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python37364bit4db73d59933341feaa47a8db6a2db2c7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
